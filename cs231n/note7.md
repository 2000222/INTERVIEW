### Gradient Checks
梯度检查很重要，并且也很容易出错。

**使用正确的表达式**
使用$ \frac{df(x)}{dx} = \frac{f(x+h)-f(x-h)}{2h} $而不是$ \frac{df(x)}{dx} = \frac{f(x+h)-f(x)}{h} $。h是非常小的数值，如1e-5。第一种表达式是中心化的，需要两个输出才能衡量梯度。

**使用相对误差**
比较数值梯度和解析梯度的时候，如果是直接使用L1或者L2距离，然后超过一个阈值就算作出现误差，那么这是有问题的。假如数值梯度和解析梯度之间的误差是1e-4，如果梯度的范围在1附近，那么我们可以看做解析梯度没有问题，但是如果梯度的数值都在1e-5附近，那么就有问题了。所以要使用相对误差$$ \frac{|f'_a-f'_n|}{\max(|f'_a|, |f'_n|)} $$。相对误差考虑了两者个梯度的范围，分母将两者相加也可以，总之要避免除0（两者其中之一可能为0）。在实践中：
 - 相对误差>1e-2就是有问题的了
 - 1e-2>相对误差>1e-4也不是很好，可能也有问题
 - 1e-4>相对误差，如果神经网络中存在左右极限不相等的点那么这个结果是可以的，但是如果函数是处处可导的这个结果是有问题的。
 - 1e-7>相对误差，这个结果是好的
 - 神经网络的深度越深，相对误差也会越高，所以10层的神经网络1e-2的相对误差也许是可以的
 
**使用Double类型**
使用单精度float检查梯度，会扩大误差，也许使用单精度相对误差是1e-2使用双精度就是1e-8了。

**仔细观察网络中的数值**
输出每层的数据查看一下，当某一层的输出变得非常小1e-10，这会导致数值问题。

**目标函数中的不可导点**
不可导点会引起准确度的问题，如ReLU中的(0, 0)点，或者SVM loss，Maxout神经元中的不可导点。

**使用少数几个数据点**
loss function中也有不可导的点，使用少数的数据进行梯度检查更快而且也不至于扩大不可导点的影响，2-3个数据就可以。

**注意h的大小**
h一般来说越小越好，越小就会引起数值问题。h为1e-4或者1e-6之间可以。

**不要让正则化淹没数据**

**关闭dropout和数据增强**

**只在少数的维度进行检测**

### 在开始学习之前
**检查loss**
先把正则化设置为0，然后看一下loss是不是合理的，例如在使用softmax的cifar-10中初始的loss应该是2.302左右，因为初始的时候神经网络相当于是乱猜测，每个类别的概率相同所以-ln(0.1)=2.302。对于SVM loss初始的loss值应该为9，因为每个错误的类别都有一个margin=1，如果初始的loss不是这个的话那么参数的初始化可能就有问题了。

然后检查增加正则化力度是否增加了loss的值。

**先再小数据集上过拟合**
先试一试在只有20个样本的数据集上进行过拟合，检查神经网络是否能达到接近0的loss，同样这时候也设置正则化为0。当然也有可能在小数据集上能够过拟合，代码也许仍然是有问题的。

### 小心照顾学习的过程
在训练的过程中应该关注着神经网络，关注每个epoch中的变化，比关注每个batch要好一些，因为每个batch多少个数据是随着batch_size的设定的。关注随着epoch增加loss的下降过程。
 - 当loss来回震荡地很厉害的时候，有可能是batch_size有点小，每个batch中的噪声较大，当batch size是1的时候震荡会最严重（会让神经网络向局部最优的方向前进），当batch size是整个数据集的时候震荡会最小（会让神经网络向全局最优的方向前进）。
 - 非常高的学习率会导致loss一直上升没有下降
 - 较高的学习率会导致loss下降到一个程度后难以下降
 - 合适的学习率能够一直下降到全局最优
 - 太小的学习率会导致loss下降速度缓慢
有些人会将loss取log之后制成图，这样看起来更像一条直线而不是曲线。

**训练/验证准确率**
如果验证集上的准确率比训练集上的小表示已经出现了过拟合。解决过拟合的方法当然是使用drpout或者L2正则化或者使用更多的数据。

**权重的更新程度**
另一个要跟踪的数据就是权重更新的量级和权重本身的量级，权重更新的程度不是梯度本身的程度还要乘上学习率。更新的程度/权重本身的量级应该在1e-3附近。如果小于这个数字，那么是学习率太低了，如果高于这个数字就是学习率太高了。相较于使用最大最小值，更常用的是计算参数的norm和更新程度的norm。当然他们的效果都差不多。
```python
# 参数矩阵W以及它的导数dW
param_scale = np.linalg.norm(W.ravel()) # ravel()将矩阵展成一维
update = -learning_rate*dW # simple SGD update
update_scale = np.linalg.norm(update.ravel())
W += update # the actual update
print update_scale / param_scale # want ~1e-3
```

**激活的神经元/梯度的分布**
一个不好的初始化可能会导致学习过程变慢，一个解决的方法就是绘制神经网络中每一层的activation/gradient直方图。如果看到什么奇怪的分布的话就不好了，比如使用tanh的话这一层的输出如果均匀的分步在[-1, 1]之间的话是正常的，如果全是0或者集中在-1 1这两个点的就不正常了。

**第一层参数做可视化**
如果可视化的结果是很粗糙并且杂乱的，那么就不好。如果是光滑的，并且有明显条纹的就是好的。

### 更新参数
梯度的解析值一旦计算出来就是更新参数了。

## SGD及其各种变体

**普通的SGD**
```python
x += -learning_rate * dx
```

**加上动量**
增加动量之后有更快的拟合速度。动量可以从物理的角度来解释，loss的下降过程可以看做是在多山的丘陵地带往山底走。初始时随机参数相当于在山上随机找个位置静止站着，优化的过程可以看做是从山上滚下来的过程。在山上的每个位置收到的力和所处位置相关($ U = mgh, F = -\nabla U $)，这个自然就是梯度了。但同时从原来的地方滚下来的时候，物体还在原来的方向上有动量(上次更新的方向)。所以滚到新的位置的时候，速度应该是现在收到的力和原来的动量相加。
```python
v = mu * v - learning_rate * dx # 速度相加
x += v # 更新后的位置进行相加
```
mu代表的是动量momentum，一般设置为0.9即可。交叉验证的时候一般在[0.5, 0.9, 0.95, 0.99]中进行查找。使用动量某种意义上也代表学习会一直进行，一旦开始动量会存在很长时间。动量和学习率的退火过程很像。一种方法是先设置动量为0.5然后逐步增加到0.99.
动量的方法让每次更新都不只是一个方向。

**Nesterov动量**
这是动量的一种特殊版本，最近开始流行，在凸优化方法有着良好的理论和实践。并且它的效果比普通的动量要好。之前是先求得更新的程度(学习率先乘以导数)，这里是先让x+=mu*v，相当于让x先沿着之前的向量走一步。然后再更新。
```python
x_ahead = x + mu * v
# evaluate dx_ahead (the gradient at x_ahead instead of at x)
v = mu * v - learning_rate * dx_ahead
x += v
```
或者是这样写
```python
v_prev = v # back this up
v = mu * v - learning_rate * dx # velocity update stays the same
x += -mu * v_prev + (1 + mu) * v # position update changes form
```

**学习率退火**
直观理解学习率退火：有着较高学习率的神经网络总有很高的能量，让它在山坡上难以下来，去到最优的点。但是何时降低学习率是一个问题，如果缓慢的一点一点降低学习率可能会浪费计算量。但是在关键点降低学习率将会加速学习的过程：
 - 阶段性降低，设置里程碑，如每隔20epoch降低0.1
 - 指数降低$ \alpha = \alpha_0e^{-kt} $，其中$ \alpha k $是超参数，t是迭代次数，当然也可以使用epoch数
 - 1/t降低$ \alpha = \alpha_0(1 + kt) $其中$\alpha k$是超参数 t是迭代次数
在实践的过程中一般阶段性降低更好。

### 二阶方法
流行的二阶优化方法是[牛顿法](https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization)：$$ x \leftarrow x - [Hf(x)]^{-1}\nabla f(x) $$其中$ Hf(x) $是黑塞矩阵，是方程的二阶导数方阵。但是目前使用牛顿法来优化不现实，因为涉及到的计算量太大了。

### 自动调整学习率
在训练的过程中根据情况全局调整学习率代价比较大，所以有了自动调整学习率的算法。大多数这种算法都是需要额外的超参数，但是也比一般的SGD效果好很多。

**Adagrad**
```python
# x是参数dx是导数
cache += dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
```
cache的size和x是一样的，它用于跟踪之前的所有梯度的平方。注意到当梯度变大的时候有效的学习率其实是降低的，当有小的梯度的时候学习率更有效。并且梯度的平方再开方这一点是很关键的，不是先平方再开方的话算法的效果会很差。eps通常设置为1e-4~1e-8之间，用于防止除零。缺点就是它的学习率不是单调下降的，这会导致学习得到提前终止。

**RMSprop**
这个方法还没有正式的发表，如果工作中使用了的话需要去引用Geoff Hinton的Coursera课程。PMSProp对Adagrad进行了一点微调。
```python
cache = decay_rate * cache + (1 - decay_rate) * dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
```
decay_rate是一个超参数，通常为[0.9, 0.99, 0.999].

**Adam**
Adam有点像RMSProp，最近才被提出。
```python
m = beta1*m + (1-beta1)*dx
v = beta2*v + (1-beta2)*(dx**2)
x += - learning_rate * m / (np.sqrt(v) + eps)
```
最后一行和RMSProp中的一样，只不过 使用了m而不是原始的梯度。论文中推荐的超参数是eps=1e-8, beta1=0.9, beta2=0.99。Adam是被推荐的默认的优化方法，比RMSProp要好，不过也可以尝试SGD+Nesterov Momentum试一试。

完全的Adam还包含了一个偏差纠正机制，是为了补偿m，v所以开始的几次m，v都是被初始化的，因此偏差是0，这样他们就完全warm-up了
```python
# t is your iteration counter going from 1 to infinity
m = beta1*m + (1-beta1)*dx
mt = m / (1-beta1**t)
v = beta2*v + (1-beta2)*(dx**2)
vt = v / (1-beta2**t)
x += - learning_rate * mt / (np.sqrt(vt) + eps)
```

### 超参数优化
神经网络主要的的超参数：
 - 初始的学习率
 - 学习率下降的策略
 - 正则化力度labmda
 - dropout概率
当然除了这些还有其他的影响较小的超参数。

**Implementation**
大型的神经网络训练时间很长，所以进行超参数的优化可能需要花费数周的时间。当然实现一个自动改变超参数并且进行训练的控制代码worder也是很方便的。控制代码worker自动追踪每个epoch之后在验证集上的准确率并且自动的保存checkpoint。然后有一个的master在服务器集群上对每个worker进行控制，及时检查checkpoint并且绘制训练相关的图表。

**超参数的范围**
在log的尺度上搜寻合适的超参数，比如学习率的搜索可以```learning_rate = 10 ** uniform(-6, 1)```其实就是[1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10]中去寻找。正则化力度lambda同样可以这样搜索。

**grid search**
虽然对于神经网络来说[随机搜索超参数比网格化搜素更有效](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)，但是这也是一种常用的方法。

**小心超参数范围的边界**
确保在范围内搜索到的超参数不是在范围的边界，如学习率在1e-6~10之间进行搜索，那么如果最优的学习率如果是1e-6的话，应该再去更小的数值进行搜索。

**分阶段从粗糙到精细调整超参数**
在调整的过程中慢慢缩小范围，一开始是在10**[-6, 1]之间，然后缩小。最后找到最优的超参数。

**利用贝叶斯来寻找最优超参数**
在卷积神经网络里使用的仍然较少。卷积神经网络使用的还是随机搜素更多一点。

### Evaluation
在实践中，最后能够提升一点效果的就是训练多个神经网络然后进行集成，测试的时候对多个结果取平均。当模型越不相同的时候集成的效果越好。
 - **相同的模型，不同的初始化**使用交叉验证决定最好的超参数，然后用最好的超参数去训练多个不同随机初始的模型。但是模型之间的不同仅仅在于初始化。
 - **交叉验证发现模型**使用交叉验证发现最好的几个模型进行集成。但是这样可能会有不达标的模型存在。但在实践中这样很方便。
 - **同一个模型的不同checkpoint**如果训练起来十分耗时，那么可以使用同一个模型的不同checkpoint进行集成。这样缺少了一些不同variety，但是实践中仍然是合理的，这种方法最方便。
 - **使用checkpoint的参数的均值**可以这么理解(/滑稽)，loss函数是一个碗状，然后两边取平均就掉进最优点了。