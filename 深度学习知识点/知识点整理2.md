### 这些层如何进行反向传播？
1. conv
2. pooling
3. deconv

对于卷积层，假如在feature map M0上进行卷积得到feature map M1，卷积核大小为k_s，那么M1[0, 0]进行反向传播，先将梯度复制成k_s*k_s份，对应位置相乘后的梯度，然后每个对应位置求对W的偏导，求对M0[i,j]的偏导。同时因为卷积核在整个M0上都进行了卷积，所以最终对W的参数是各个位置上的梯度相加。

对于Pooling层都没有需要学习的参数。因此在反向传播的时候pooling层仅仅是将梯度传递到上一层，而没有梯度的计算。如果是Max Pooling则将梯度传播到上一层对应的区域中最大值的神经元处，其他的神经元的梯度都是0.如果是Mean Pooling那么下一层的梯度会平均分配到上一层对应区域的所有神经元处。

反卷积Deconvolution也称作卷积的转置Transposed Convolution实际上就是先对原feature map M0进行加上边，然后进行卷积使得输出的size变成需要的输出M1。对于边上的值是不需要求出导数的，因为这些边上的值反向也没有地方可以传播。对于那些原来的值，求出导数后进行反向传播。

### 解释deconv的作用？
1. 在语义分割中使用，上采样upsampling，将较小的feature map扩大。
2. CNN可视化，通过deconv将CNN中conv得到的feature map还原到像素空间，以观察特定的feature map对哪些pattern敏感。
3. 无监督学习，或者是GAN中，进行重建图片。

### 什么是bottle-neck结构？
bottle-neck是一种将信息压缩再放大的神经网络结构。这种结构很常见如：自编码器。bottle-neck的典型结构如下：

 - 1x1卷积，用来降低channel数，feature map的size不变
 - 3x3卷积，对小的feature map进行尺度不变channel不变的卷积
 - 1x1卷积，恢复channel数

一般而言，一个(1x1, 3x3, 1x1)的bottle-neck结构比两个连续的3x3卷积效果要好。虽然bottle-neck结构损失了信息，但数据中本来就冗余有大量的信息。bottle-neck获得的中间特征固然是低维的/去噪的，但是同自编码器一样可以用来恢复大部分的信息。

### 深度学习中有什么加快收敛/降低训练难度的方法？
 - 瓶颈结构
 - 残差结构
 - 使用高级的优化方法如Adam，或者SGD加上Nestrov动量
 - 适当调整学习率
 - 进行预训练

### 为什么机器学习中都希望数据独立同分布？
 - 如果数据样本之间不独立那么意味着有共线性的存在，这会导致过拟合。
 - 如果数据样本不处于同一个分布，那么会导致特征的各个维度的尺度不一（量纲不同）会导致训练速度减慢、局部最优等问题。

解决的方法有对数据进行PCA白化、深度学习中有BN（1加快学习 2防止过拟合 3预防梯度消失爆炸 4解决）。其实在采样得到mini-batch的时候也会导致batch中的数据分布和整体不太一样。

### 空洞卷积 dilation conv？
空洞卷积是在卷积核之间加入空洞，这样扩大感受域并且也没有增加参数。空洞卷积默认普通的卷积卷积核中每个cell之间相隔的位置是1.应用在图像分割领域中，在进行上采样的时候通过反卷积来增大feature map的size，当然这样会损失信息。但是使用空洞卷积，增大感受域的同时没有太多的信息损失。

### 池化层？
一般来说有max pooling、average pooling、L2norm pooling，最常用效果最好的还是max pooling。池化是为了降低特征的维度，去掉冗余的信息，控制过拟合。

最大池化为什么要取最大值呢？因为在这个filter的区域中，值越大表示和filter响应的程度越高，是特征的主要组成部分，而其他部分基本上都是冗余的信息。

### 迁移学习？
利用之前在其他数据集上学习到的知识在新的数据集上进行微调。当新的数据集较大的时候，可能只需要重新训练最后一个全连接层，而前面的层都冻结起来。当新的数据集较大的时候需要重新训练最后的所有全连接层（一般是三个）并且前面的卷积层也都需要用很小的学习率进行学习。
| . | 较相同的数据集 | 较不同的数据集 |
| 很少的数据 | 重新训练最后一个全连接层 | 很麻烦，尝试从不同的地方开始重新训练 |
| 很多的数据 | 微调倒数几层 | 微调很多层 |

### Inception结构？
最简单的Inception结构：假如输入为(28, 28, 256)，然后分成四个部分：

 - 1x1 conv 128 channel
 - 1x1 conv less channel, 3x3 conv 192 channel
 - 1x1 conv less channel, 5x5 conv 96 channel
 - 1x1 conv less channel, 3x3 pool 256 channel

这些层的输出size都不变，那么再把他们concatenation起来变成(28, 28, 672)。缺点是计算量太大，输出的channel数太多，但是这个可以通过bottle-neck结构来解决。在输入3x3 5x5卷积层之前进行1x1卷积，降低channel数。

对于卷积来说，卷积核可以看做一个三维的滤波器：通道维+空间维（Feature Map 的宽和高），常规的卷积操作其实就是实现通道相关性和空间相关性的联合映射。Inception 模块的背后存在这样的一种假设：卷积层通道间的相关性和空间相关性是可以退耦合的，将它们分开映射，能达到更好的效果

假设 Input 是 28×28×192 的 Feature Maps，在通道相关性上利用 32 个 1×1×192 的卷积核做线性组合，得到 28×28×32 大小的 Feature Maps，再对这些 Feature Maps 做 256 个 3×3×32 的卷积，即联合映射所有维度的相关性，就得到 28×28×256 的 Feature Maps 结果。可以发现，这个结果其实跟直接卷积 256 个3×3×192 大小的卷积核是一样。

也就是说，Inception 的假设认为用 32 个 1×1×192 和 256 个 3×3×32 的卷积核退耦级联的效果，与直接用 256个 3×3×192 卷积核等效。而两种方式的参数量则分别为32×1×1×192 + 256×3×3×32 = 79872 和 256×3×3×192 = 442368。

在**深度可分离卷积**方面，Inception的思想和MobileNet很相似，但是MobileNet（用的就是深度可分离卷积）是先在depth-wise上进行卷积再进行point-wise卷积。

### 存储神经网络消耗的内存和权重消耗的内存分别集中在哪些部分？
存储神经网络内存主要是存储每层的输出，集中在前个卷积层的输出中。而权重消耗的内存主要集中在最后的全连接层中。

### 训练一个神经网络，一开始loss没有下降，过了几个epoch开始快速下降，可能是什么原因？
 - 陷入局部最小值
 - 学习率过小，这个时候一开始实际上是从局部最小值中走出来的这个过程
 - 正则参数过高

### 什么造成了过拟合？用什么方法来预防过拟合？
过拟合就是在训练集上的效果比在验证集上的效果要好。

造成过拟合的原因：

 - 样本数量太多
 - 参数过多，模型太大
 - 迭代次数过多，模型学习了训练集上的噪音

消除过拟合的方法：

 - 提前终止训练
 - 使用较小的模型
 - 使用正则化（weight decay），每次更新的时候$ w_i \leftarrow w_i - \eta \frac{\partial{E}{\partial{w_i}} - \lambda W $其中$ \lambda $就是weight decay的程度。

### ResNet优缺点及适用范围？
对ResNet的解释：

 - 网络在某些层学习到了恒等变换。在某些层执行恒等变换是一种构造性解，使得更深的模型的性能至少不少于较浅层的模型。这也是原始论文中的解释。
 - 残差网络是很多浅层网络的集成，集成的模型的数量是层数的指数级那么多。将其中的某些层直接删掉对最终的结果影响不大。[Residual Networks Behave Like Ensembles of Relatively Shallow Networks](https://arxiv.org/abs/1605.06431)
 - 残差网络使得信息更容易在各层之间流动，包括在前向传播时提供特征重用，在反向传播时缓解梯度消失。[Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf)

在《Identity Mappings in Deep Residual Networks》中何凯明又对shortcut进行和各种实验，实验结果是shortcut什么都不做进行恒等变换的效果最好，然后在主干道中进行```BN -> ReLU -> conv```的效果最好。

### InceptionNet优缺点及适用范围？
引入Inception module，但是并没有VGG ResNet那样出名。因为超参数太多，每个module具体要怎么进行设计都要考虑，但其实效果也很不错。

### DenseNet优缺点及适用范围？
DenseNet很大的创新点就是各层的特征进行大融合，但是这些特征也是有冗余的。densenet也相当于浪费了很多的计算资源。而且DenseNet利用中间层就可以进行预测这一点更证实了这一点。

### 调参有什么技巧？
对于网络：

 - 先让网络在小数据集上进行过拟合，让准确率达到非常高，看看整体有没有问题。模型是否有足够的表示能力等。
 - 网络结构的话，激活函数一般就用ReLU，还有使用Batch Norm、dropout等，参照在各种比赛中取得名次的网络结构
 - 训练之前先观察数据，各个类别的分布，最好对数据有个直观的认识，然后考虑数据增强等

对于优化：

 - 先使用Adam，如果是从头训练的话，学习率一般设为1e-3，如果用的是预训练的模型则根据不同的情况来微调
 - Adam效果不好就换SGD+Momentum momentum一般我们会选择0.9-0.95之间，weight decay我们一般会选择0.005
 - 逐步下降学习率，如果当前的学习率已经不能让loss下降，那么就*1/10

### 为什么机器学习、深度学习都需要用概率论来进行解释？
因为机器学习通常必须处理不确定的量，如果是直接确定的话直接构造一个确定的分布就可以进行预测。不确定量主要来源于：

 - 被建模系统内在的随机性。如玩纸牌游戏，每次抽到的纸牌不可能是确定的。
 - 不完全观测。对数据的不完全观测。
 - 不完全建模。部分的数据无法进行预测。

### TensorFlow
使用数据流图来规划计算流程，它可以将计算映射到不同的硬件和操作系统平台。TensorFlow可以应用在大规模的深度学习中，也可以应用在小规模的应用中。TensorFlow抽象出来的数据流图也可以用在通用数值计算和符号计算上，比如分形图计算或者偏微分方程数值求解。

### RCNN系列的发展过程？
Region based CNN，一开始是根据selective search用一个滑窗滑遍整个图片，对与每个滑窗滑到的位置输入CNN来判断是哪个物体以及物体的x、y、h、w，这样的方式会对部分区域进行大量的重复计算，开销太大。

Fast RCNN，将经过几次卷积的高级特征看作是对图像的压缩，在高级特征上面做ROI Pooling：先selective-search，proposal出一个高级特征的区域，这个区域输入接下来的神经网络来进行判断。输入神经网络后分叉得到物体的类别和位置，这是个multi-task。

Faster RCNN，Fast RCNN仍然是在feature map每个位置上proposal，然后都输入接下来的网络，这样是很低效的。于是有了RPN Region Proposal Network，把feature map输入RPN，让它进行proposal。RPN就是在feature map上进行滑动，输出这个位置是物体/背景，以及x、y、h、w。如果是物体才把feature map上的区域输入接下来的神经网络，如果是背景就不输入接下来的神经网络。物体的位置也会进一步修正。

典型的SSD中MultiBox的部分的计算量是比backbone的计算量要大的。在具体的应用场景中，要看设计了几个multibox，multibox少的时候计算量少。

### RNN LSTM GRU区别
[LSTM原理及实现](https://blog.csdn.net/gzj_1101/article/details/79376798)

[RNN LSTM与GRU深度学习模型学习笔记](https://blog.csdn.net/softee/article/details/54292102)

RNN被称为是并发的，是因为传统的神经网络中，输入是相互独立的，但是在RNN中不是这样的，一个语句分多次，每次一个单词输入RNN，每次都是使用同样的方式进行处理，每次处理也都依赖于之前的计算。

LSTM是为了解决RNN中的反馈小时问题而被提出的模型，它也可以被视为一个RNN的变种，增加了三个们输入门、遗忘门、输出门。门机制的存在，使得LSTM能够显示地为序列中长距离的依赖关系进行建模。

GRU与LSTM类似，但是更为简化。GRU中只有两个门，一般认为LSTM和GRU之间没有明显的优胜者。但是GRU具有较少的参数，所以速度快，而且所需要的样本较少，LSTM具有较多的参数，比较适合大量样本的情况。

### SSD与Faster RCNN
ssd是class aware，rpn是class agnostic。ssd分层出，其实就这些。class agnostic指的就是先判断这个anchor是不是物体，是物体就输入接下来的神经网络。而SSD则直接全部进行输入接下来的神经网络。然后进行非极大值抑制，训练的时候还要进行hard mining。

SSD与Faster RCNN难在Loss部分，坐标回归可以使用SmoothL1Loss、分类可以使用交叉熵。但是预测出来的很多个位置和置信度怎么和标签对应上呢？

一般来说一个图片有1个标签或多个表现为```[num, x, y, w, h] [num, class]```，利用这些标签产生prior_box，prior_box的个数就是训练的时候输出的anchor的个数。假如说原图为300x300，有2个planes为50x50、15x15，每个位置有3个ratio的box，这样2个plane就会产生50x50x3+15x15x3=8175个anchor。在图片输入神经网络得到结果之前，这些anchor叫做prior box：```[8175, x, y, w, h]```。在输入神经网络之前，标签要和prior box进行match，计算每个标签和8175个prior box之间的重叠程度，只有达到一定的重叠程度才认为这个prior box有物体，然后就把这个prior box的```x, y, w, h```置为标签的值（实际计算位置loss的时候会忽略背景box），```class```置为重叠程度最大的标签的类别，如果重叠程度太低就是背景的类别。所以在我们的例子里用于计算loss的label实际上是prior box中的非背景的几个box。

SSD中在计算loss的时候，先筛选出输出结果中的非背景box```[x, y, w, h]```，然后和prior box中的非背景box计算SmoothL1Loss。在计算类别损失的时候，所有的prior box全部和输出的anchor计算交叉熵，因为其中包含了太多的背景类所以不适合进行反向传播，所以对cross_entropy_loss进行hard mining选出一部分loss最大的背景类的box（表示这几个box容易被神经网络看错，难以进行区分），和非背景类的一起反向传播。

[Faster-RCNN代码+理论——1](https://blog.csdn.net/g11d111/article/details/78823663)

[ROI Pooling原理及实现](https://blog.csdn.net/u011436429/article/details/80279536)

### harding mining
hard negative mining就是每次把那些顽固的棘手的错误,再送回去继续训练,从而加强分类器判别假阳性的能力。

### NMS非极大值抑制
使用目标检测算法检测出来会有很多框，并且很多框都是重叠的，这个时候需要将框合并。由于是在inference的时候进行NMS，所以对速度的要求是很高的，一般使用Cython或者CUDA编写NMS部分代码。输出的大量Bounding Box包含了位置和置信度，利用这些信息将重叠程度高的box消除掉。

NMS算法流程：

1. 将box按照置信度由大到小进行排序，得到列表
2. 循环：
   - 从列表中取出置信度最大的box放进最终要保留的box集合中
   - 计算列表中剩余所有box和这个放进保留集合中的box的IOU
   - 去掉IOU超过一定阈值的box
3. IOU = 交集/并集

### 目标检测中的感受野
当目标检测中backbone中的某层feature map的一个cell的感受野匹配所要检测的物体的大小的时候就可以进行multibox输出来检测到这个物体，否则神经网络是看不到这个物体的。

因为越靠前的卷积，其感受野越小，越有利于小物体的识别。但是感受野小就检测不出来大物体。

在SSD中backbone一般使用的是VGG16，然后就是连续的卷积，其中不同大小的feature map作为候选的feature map set。然后MultiBox Layer作用于这些feature map上，输出每个位置不同比例的框的```x, y, w, h```以及类别。

SSD认为目标检测中的物体，只与周围信息相关，它的感受野不是全局的，故没必要也不应该做全连接。全连接的话，每个神经元的感受野都是全局的。

[关于感受野的总结](https://cloud.tencent.com/developer/article/1179175)

[卷积神经网络物体检测之感受野大小计算](https://blog.csdn.net/u014696921/article/details/53791327)

[带你深入AI（4）- 目标检测领域：R-CNN，faster R-CNN，yolo，SSD, yoloV2](https://blog.csdn.net/u013510838/article/details/79947553)

### 有效感受野和理论感受野
影响某个神经元输出的区域就是理论感受野，也就是平常说的感受野。但是输入区域的每个点对输出的影响程度不同，越靠近中心的像素点影响越大，呈高斯分布，也就是只有输入的中间的一小部分对最后的输出有重要影响，这个中间部分就是有效感受野。

SSD中通过设置default box来人为确定一个神经网络想要看到的部分，所以default box的大小要和有效感受野大小匹配。由于default box只要匹配实际的有效感受野就可以了，而实际的有效感受野要比理论感受野小很多。所以SSD中每一层的default box的大小可以比理论感受野小很多。所以SSD继续优化的一个方向就是让default box匹配实际感受野。

SSD的一个缺点就是对小物体的检测效果不好，因为感受野的原因。使用VGG中靠前的部分来进行预测可以解决这个问题。

### 为什么设置多种宽高比的default box
default box实际上是SSD的标签，如果只设置了宽高比为1的default box，那么对于这个位置只有一个default box能够匹配到，如果设置更多的宽高比的default box，将会有更多的default box匹配到。

[SSD原理解读-从入门到精通](https://blog.csdn.net/qianqing13579/article/details/82106664)这篇文章写的很好，一定要读一下。

### 感受野和设计anchor之间的关系
现在流行的目标检测网络大部分都是基于anchor的，比如SSD、faster rcnn。基于anchor的目标检测网络会预设一组不同大小的anchor，比如32x32，64x64，128x128，256x256，这么多的anchor应该放在卷积中的哪几层合适呢？

这个时候就要考虑感受野的问题了。放置anchor层的实际感受野应该和anchor大小匹配，实际感受野比anchor大太多不好，比anchor太小也不好。

[设计深度卷积神经网络的实用技巧理论](https://blog.csdn.net/JosephPai/article/details/81235310)

### 目标检测中的数据增强
[CV_ToolBox/DataAugForObjectDetection/DataAugmentForObejctDetection.py](https://github.com/maozezhong/CV_ToolBox/blob/master/DataAugForObjectDetection/DataAugmentForObejctDetection.py)

### Mobilenet
MobileNet 是Google推出的一款高效的移动端轻量化网络，其核心就是深度可分离卷积。它的思想和Inception相同，卷积层通道间的相关性和空间相关性是可以退耦合的，将它们分开映射，能达到更好的效果。

假设输入的图片为(224, 224, 3)，传统的3x3卷积的卷积核为(3, 3, 3, 32) (H, W, in_channel, output_channel)。而深度分离卷积则是:

1. (3, 3, 1, 3) -> output: (112, 112, 3) 深度卷积（depth-wise），每个channel有一个对应的卷积核（这个卷积核是2D的）。
2. (1, 1, 3, 32) -> output: (112, 112, 32) 点卷积（point-wise），所有channel用的是同一个卷积核（这个卷积核是3D的）。

[mobilenet网络的理解](https://blog.csdn.net/wfei101/article/details/78310226)

[深度可分离卷积（Xception 与 MobileNet 的点滴）](https://www.jianshu.com/p/38dc74d12fcf)

[对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解](https://blog.csdn.net/chaolei3/article/details/79374563)

[变形卷积核、可分离卷积？卷积神经网络中十大拍案叫绝的操作。](https://zhuanlan.zhihu.com/p/28749411)

### Mobilenet v1 v2 区别
mobilenetv1 和v2的主要区别就是：

V1:                   --> 3x3 DW --ReLU6--> 1x1 PW --ReLU6-->

V2: --> 1x1 PW --ReLU6--> 3x3 DW --ReLU6--> 1x1 PW --Linear-->

V2中：

1. 1x1卷积进行扩张，目的是为了提升通道数，获得更多的特征。
2. 最后不采用ReLU，而是Linear，目的是防止ReLU破坏特征。

### 深度可分离卷积节省的计算量
一个传统的卷积操作，假设卷积核大小是K，输入的feature map的channel是M，输出的feature map是(F, F, N)长和宽都是F，channel是N，那么这个卷积所需要的计算量是K\*K\*M\*F\*F\*N。

现在将卷积分解为depth wise和point wise的卷积。假设输入和输出都和上面是一样的，其中depth wise的卷积的计算量为K\*K\*1\*F\*F\*M，point wise的计算量是M\*F\*F\*N。

### 视频帧相关
国内的PAL制式是25帧，国外的NTSC制式是30帧。电影一般是24帧或者30帧。这里的帧指的都是关键帧。在进行检测的时候抽取的也都是关键帧。